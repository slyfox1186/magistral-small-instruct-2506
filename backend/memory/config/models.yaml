# Embedding Model Configuration
embedding:
  # Primary model
  primary:
    name: BAAI/bge-large-en-v1.5  # BGE-large model for production embeddings
    device: cuda
    batch_size: 32
    max_seq_length: 512
    normalize: true
    
  # Model versioning
  versioning:
    current_version: "v1.0"
    model_path: /models/embeddings/current  # Symlink to active model
    versions_path: /models/embeddings/versions/
    
  # Cache settings
  cache:
    enabled: true
    max_size: 1000
    ttl_seconds: 3600
    
# LLM for consolidation
consolidation_llm:
  model_path: /home/jman/tmp/models-to-test/Magistral-Small-2506-1.2/backend/models/
  context_size: 4096
  temperature: 0.7
  max_tokens: 512
  
# Performance optimization
optimization:
  use_fp16: true  # Half precision for memory efficiency
  compile_model: true  # Torch compile for speed
  num_threads: 4